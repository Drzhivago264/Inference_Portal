import { z } from "zod";
import { BaseCallbackConfig, CallbackManagerForLLMRun, CallbackManagerForToolRun } from "../../callbacks/manager.js";
import { BaseChatMessageHistory, BaseListChatMessageHistory } from "../../chat_history.js";
import { Document } from "../../documents/document.js";
import { BaseChatModel, BaseChatModelParams } from "../../language_models/chat_models.js";
import { BaseLLMParams, LLM } from "../../language_models/llms.js";
import { BaseMessage, AIMessage } from "../../messages/index.js";
import { BaseOutputParser } from "../../output_parsers/base.js";
import { GenerationChunk, type ChatResult, ChatGenerationChunk } from "../../outputs.js";
import { BaseRetriever } from "../../retrievers/index.js";
import { Runnable } from "../../runnables/base.js";
import { StructuredTool, ToolParams } from "../../tools.js";
import { BaseTracer, Run } from "../../tracers/base.js";
import { Embeddings, EmbeddingsParams } from "../../embeddings.js";
import { StructuredOutputMethodParams, BaseLanguageModelInput, StructuredOutputMethodOptions } from "../../language_models/base.js";
/**
 * Parser for comma-separated values. It splits the input text by commas
 * and trims the resulting values.
 */
export declare class FakeSplitIntoListParser extends BaseOutputParser<string[]> {
    lc_namespace: string[];
    getFormatInstructions(): string;
    parse(text: string): Promise<string[]>;
}
export declare class FakeRunnable extends Runnable<string, Record<string, any>> {
    lc_namespace: string[];
    returnOptions?: boolean;
    constructor(fields: {
        returnOptions?: boolean;
    });
    invoke(input: string, options?: Partial<BaseCallbackConfig>): Promise<Record<string, any>>;
}
export declare class FakeLLM extends LLM {
    response?: string;
    thrownErrorString?: string;
    constructor(fields: {
        response?: string;
        thrownErrorString?: string;
    } & BaseLLMParams);
    _llmType(): string;
    _call(prompt: string, _options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): Promise<string>;
}
export declare class FakeStreamingLLM extends LLM {
    sleep?: number;
    responses?: string[];
    thrownErrorString?: string;
    constructor(fields: {
        sleep?: number;
        responses?: string[];
        thrownErrorString?: string;
    } & BaseLLMParams);
    _llmType(): string;
    _call(prompt: string): Promise<string>;
    _streamResponseChunks(input: string): AsyncGenerator<GenerationChunk, void, unknown>;
}
export declare class FakeChatModel extends BaseChatModel {
    _combineLLMOutput(): never[];
    _llmType(): string;
    _generate(messages: BaseMessage[], options?: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;
}
export declare class FakeStreamingChatModel extends BaseChatModel {
    sleep?: number;
    responses?: BaseMessage[];
    thrownErrorString?: string;
    constructor(fields: {
        sleep?: number;
        responses?: BaseMessage[];
        thrownErrorString?: string;
    } & BaseLLMParams);
    _llmType(): string;
    _generate(messages: BaseMessage[], _options: this["ParsedCallOptions"], _runManager?: CallbackManagerForLLMRun): Promise<ChatResult>;
    _streamResponseChunks(messages: BaseMessage[], _options: this["ParsedCallOptions"], _runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;
}
export declare class FakeRetriever extends BaseRetriever {
    lc_namespace: string[];
    output: Document<Record<string, any>>[];
    constructor(fields?: {
        output: Document[];
    });
    _getRelevantDocuments(_query: string): Promise<Document<Record<string, any>>[]>;
}
/**
 * Interface for the input parameters specific to the Fake List Chat model.
 */
export interface FakeChatInput extends BaseChatModelParams {
    /** Responses to return */
    responses: string[];
    /** Time to sleep in milliseconds between responses */
    sleep?: number;
}
/**
 * A fake Chat Model that returns a predefined list of responses. It can be used
 * for testing purposes.
 * @example
 * ```typescript
 * const chat = new FakeListChatModel({
 *   responses: ["I'll callback later.", "You 'console' them!"]
 * });
 *
 * const firstMessage = new HumanMessage("You want to hear a JavaScript joke?");
 * const secondMessage = new HumanMessage("How do you cheer up a JavaScript developer?");
 *
 * // Call the chat model with a message and log the response
 * const firstResponse = await chat.call([firstMessage]);
 * console.log({ firstResponse });
 *
 * const secondResponse = await chat.call([secondMessage]);
 * console.log({ secondResponse });
 * ```
 */
export declare class FakeListChatModel extends BaseChatModel {
    static lc_name(): string;
    responses: string[];
    i: number;
    sleep?: number;
    constructor({ responses, sleep }: FakeChatInput);
    _combineLLMOutput(): never[];
    _llmType(): string;
    _generate(_messages: BaseMessage[], options?: this["ParsedCallOptions"]): Promise<ChatResult>;
    _formatGeneration(text: string): {
        message: AIMessage;
        text: string;
    };
    _streamResponseChunks(_messages: BaseMessage[], _options: this["ParsedCallOptions"], runManager?: CallbackManagerForLLMRun): AsyncGenerator<ChatGenerationChunk>;
    _sleepIfRequested(): Promise<void>;
    _sleep(): Promise<void>;
    _createResponseChunk(text: string): ChatGenerationChunk;
    _currentResponse(): string;
    _incrementResponse(): void;
    withStructuredOutput<RunOutput extends Record<string, any> = Record<string, any>>(_params: StructuredOutputMethodParams<RunOutput, false> | z.ZodType<RunOutput> | Record<string, any>, config?: StructuredOutputMethodOptions<false>): Runnable<BaseLanguageModelInput, RunOutput>;
    withStructuredOutput<RunOutput extends Record<string, any> = Record<string, any>>(_params: StructuredOutputMethodParams<RunOutput, true> | z.ZodType<RunOutput> | Record<string, any>, config?: StructuredOutputMethodOptions<true>): Runnable<BaseLanguageModelInput, {
        raw: BaseMessage;
        parsed: RunOutput;
    }>;
}
export declare class FakeChatMessageHistory extends BaseChatMessageHistory {
    lc_namespace: string[];
    messages: Array<BaseMessage>;
    constructor();
    getMessages(): Promise<BaseMessage[]>;
    addMessage(message: BaseMessage): Promise<void>;
    addUserMessage(message: string): Promise<void>;
    addAIChatMessage(message: string): Promise<void>;
    clear(): Promise<void>;
}
export declare class FakeListChatMessageHistory extends BaseListChatMessageHistory {
    lc_namespace: string[];
    messages: Array<BaseMessage>;
    constructor();
    addMessage(message: BaseMessage): Promise<void>;
    getMessages(): Promise<BaseMessage[]>;
}
export declare class FakeTracer extends BaseTracer {
    name: string;
    runs: Run[];
    constructor();
    protected persistRun(run: Run): Promise<void>;
}
export interface FakeToolParams<T extends z.ZodObject<any, any, any, any> = z.ZodObject<any, any, any, any>> extends ToolParams {
    name: string;
    description: string;
    schema: T;
}
export declare class FakeTool<T extends z.ZodObject<any, any, any, any> = z.ZodObject<any, any, any, any>> extends StructuredTool<T> {
    name: string;
    description: string;
    schema: T;
    constructor(fields: FakeToolParams<T>);
    protected _call(arg: z.output<T>, _runManager?: CallbackManagerForToolRun): Promise<string>;
}
/**
 * A class that provides fake embeddings by overriding the embedDocuments
 * and embedQuery methods to return fixed values.
 */
export declare class FakeEmbeddings extends Embeddings {
    constructor(params?: EmbeddingsParams);
    /**
     * Generates fixed embeddings for a list of documents.
     * @param documents List of documents to generate embeddings for.
     * @returns A promise that resolves with a list of fixed embeddings for each document.
     */
    embedDocuments(documents: string[]): Promise<number[][]>;
    /**
     * Generates a fixed embedding for a query.
     * @param _ The query to generate an embedding for.
     * @returns A promise that resolves with a fixed embedding for the query.
     */
    embedQuery(_: string): Promise<number[]>;
}
/**
 * An interface that defines additional parameters specific to the
 * SyntheticEmbeddings class.
 */
interface SyntheticEmbeddingsParams extends EmbeddingsParams {
    vectorSize: number;
}
/**
 * A class that provides synthetic embeddings by overriding the
 * embedDocuments and embedQuery methods to generate embeddings based on
 * the input documents. The embeddings are generated by converting each
 * document into chunks, calculating a numerical value for each chunk, and
 * returning an array of these values as the embedding.
 */
export declare class SyntheticEmbeddings extends Embeddings implements SyntheticEmbeddingsParams {
    vectorSize: number;
    constructor(params?: SyntheticEmbeddingsParams);
    /**
     * Generates synthetic embeddings for a list of documents.
     * @param documents List of documents to generate embeddings for.
     * @returns A promise that resolves with a list of synthetic embeddings for each document.
     */
    embedDocuments(documents: string[]): Promise<number[][]>;
    /**
     * Generates a synthetic embedding for a document. The document is
     * converted into chunks, a numerical value is calculated for each chunk,
     * and an array of these values is returned as the embedding.
     * @param document The document to generate an embedding for.
     * @returns A promise that resolves with a synthetic embedding for the document.
     */
    embedQuery(document: string): Promise<number[]>;
}
export declare class SingleRunExtractor extends BaseTracer {
    runPromiseResolver: (run: Run) => void;
    runPromise: Promise<Run>;
    /** The name of the callback handler. */
    name: string;
    constructor();
    persistRun(run: Run): Promise<void>;
    extract(): Promise<Run>;
}
export {};
