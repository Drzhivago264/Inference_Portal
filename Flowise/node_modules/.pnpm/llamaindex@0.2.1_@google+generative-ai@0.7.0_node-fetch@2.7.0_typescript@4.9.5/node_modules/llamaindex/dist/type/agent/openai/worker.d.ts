import type { CallbackManager } from "../../callbacks/CallbackManager.js";
import type { ChatMessage } from "../../llm/index.js";
import { OpenAI } from "../../llm/index.js";
import type { ObjectRetriever } from "../../objects/base.js";
import type { ToolOutput } from "../../tools/types.js";
import type { BaseTool } from "../../types.js";
import type { AgentWorker, Task } from "../types.js";
import { TaskStep, TaskStepOutput } from "../types.js";
import type { OpenAIToolCall } from "./types/chat.js";
type OpenAIAgentWorkerParams = {
    tools?: BaseTool[];
    llm?: OpenAI;
    prefixMessages?: ChatMessage[];
    verbose?: boolean;
    maxFunctionCalls?: number;
    callbackManager?: CallbackManager | undefined;
    toolRetriever?: ObjectRetriever;
};
type CallFunctionOutput = {
    message: ChatMessage;
    toolOutput: ToolOutput;
};
/**
 * OpenAI agent worker.
 * This class is responsible for running the agent.
 */
export declare class OpenAIAgentWorker implements AgentWorker {
    private llm;
    private verbose;
    private maxFunctionCalls;
    prefixMessages: ChatMessage[];
    callbackManager: CallbackManager | undefined;
    private _getTools;
    /**
     * Initialize.
     */
    constructor({ tools, llm, prefixMessages, verbose, maxFunctionCalls, callbackManager, toolRetriever, }: OpenAIAgentWorkerParams);
    /**
     * Get all messages.
     * @param task: task
     * @returns: messages
     */
    getAllMessages(task: Task): ChatMessage[];
    /**
     * Get latest tool calls.
     * @param task: task
     * @returns: tool calls
     */
    getLatestToolCalls(task: Task): OpenAIToolCall[] | null;
    /**
     *
     * @param task
     * @param openaiTools
     * @param toolChoice
     * @returns
     */
    private _getLlmChatKwargs;
    /**
     * Process message.
     * @param task: task
     * @param chatResponse: chat response
     * @returns: agent chat response
     */
    private _processMessage;
    private _getStreamAiResponse;
    /**
     * Get agent response.
     * @param task: task
     * @param mode: mode
     * @param llmChatKwargs: llm chat kwargs
     * @returns: agent chat response
     */
    private _getAgentResponse;
    /**
     * Call function.
     * @param tools: tools
     * @param toolCall: tool call
     * @param memory: memory
     * @param sources: sources
     * @returns: void
     */
    callFunction(tools: BaseTool[], toolCall: OpenAIToolCall): Promise<CallFunctionOutput>;
    /**
     * Initialize step.
     * @param task: task
     * @param kwargs: kwargs
     * @returns: task step
     */
    initializeStep(task: Task, kwargs?: any): TaskStep;
    /**
     * Should continue.
     * @param toolCalls: tool calls
     * @param nFunctionCalls: number of function calls
     * @returns: boolean
     */
    private _shouldContinue;
    /**
     * Get tools.
     * @param input: input
     * @returns: tools
     */
    getTools(input: string): Promise<BaseTool[]>;
    private _runStep;
    /**
     * Run step.
     * @param step: step
     * @param task: task
     * @param kwargs: kwargs
     * @returns: task step output
     */
    runStep(step: TaskStep, task: Task, kwargs?: any): Promise<TaskStepOutput>;
    /**
     * Stream step.
     * @param step: step
     * @param task: task
     * @param kwargs: kwargs
     * @returns: task step output
     */
    streamStep(step: TaskStep, task: Task, kwargs?: any): Promise<TaskStepOutput>;
    /**
     * Finalize task.
     * @param task: task
     * @param kwargs: kwargs
     * @returns: void
     */
    finalizeTask(task: Task, kwargs?: any): void;
}
export {};
