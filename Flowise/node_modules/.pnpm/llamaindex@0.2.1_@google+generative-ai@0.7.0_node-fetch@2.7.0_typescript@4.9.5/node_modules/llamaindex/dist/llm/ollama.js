import { ok } from "@llamaindex/env";
import { BaseEmbedding } from "../embeddings/types.js";
const messageAccessor = (data)=>{
    return {
        delta: data.message.content
    };
};
const completionAccessor = (data)=>{
    return {
        text: data.response
    };
};
// https://github.com/jmorganca/ollama
export class Ollama extends BaseEmbedding {
    hasStreaming = true;
    // https://ollama.ai/library
    model;
    baseURL = "http://127.0.0.1:11434";
    temperature = 0.7;
    topP = 0.9;
    contextWindow = 4096;
    requestTimeout = 60 * 1000;
    additionalChatOptions;
    callbackManager;
    modelMetadata;
    constructor(init){
        super();
        this.model = init.model;
        this.modelMetadata = init.modelMetadata ?? {};
        Object.assign(this, init);
    }
    get metadata() {
        return {
            model: this.model,
            temperature: this.temperature,
            topP: this.topP,
            maxTokens: undefined,
            contextWindow: this.contextWindow,
            tokenizer: undefined,
            ...this.modelMetadata
        };
    }
    async chat(params) {
        const { messages, parentEvent, stream } = params;
        const payload = {
            model: this.model,
            messages: messages.map((message)=>({
                    role: message.role,
                    content: message.content
                })),
            stream: !!stream,
            options: {
                temperature: this.temperature,
                num_ctx: this.contextWindow,
                top_p: this.topP,
                ...this.additionalChatOptions
            }
        };
        const response = await fetch(`${this.baseURL}/api/chat`, {
            body: JSON.stringify(payload),
            method: "POST",
            signal: AbortSignal.timeout(this.requestTimeout),
            headers: {
                "Content-Type": "application/json"
            }
        });
        if (!stream) {
            const raw = await response.json();
            const { message } = raw;
            return {
                message: {
                    role: "assistant",
                    content: message.content
                },
                raw
            };
        } else {
            const stream = response.body;
            ok(stream, "stream is null");
            ok(stream instanceof ReadableStream, "stream is not readable");
            return this.streamChat(stream, messageAccessor, parentEvent);
        }
    }
    async *streamChat(stream, accessor, parentEvent) {
        const reader = stream.getReader();
        while(true){
            const { done, value } = await reader.read();
            if (done) {
                return;
            }
            const lines = Buffer.from(value).toString("utf-8").split("\n").map((line)=>line.trim());
            for (const line of lines){
                if (line === "") {
                    continue;
                }
                const json = JSON.parse(line);
                if (json.error) {
                    throw new Error(json.error);
                }
                yield accessor(json);
            }
        }
    }
    async complete(params) {
        const { prompt, parentEvent, stream } = params;
        const payload = {
            model: this.model,
            prompt: prompt,
            stream: !!stream,
            options: {
                temperature: this.temperature,
                num_ctx: this.contextWindow,
                top_p: this.topP,
                ...this.additionalChatOptions
            }
        };
        const response = await fetch(`${this.baseURL}/api/generate`, {
            body: JSON.stringify(payload),
            method: "POST",
            signal: AbortSignal.timeout(this.requestTimeout),
            headers: {
                "Content-Type": "application/json"
            }
        });
        if (!stream) {
            const raw = await response.json();
            return {
                text: raw.response,
                raw
            };
        } else {
            const stream = response.body;
            ok(stream, "stream is null");
            ok(stream instanceof ReadableStream, "stream is not readable");
            return this.streamChat(stream, completionAccessor, parentEvent);
        }
    }
    tokens(messages) {
        throw new Error("Method not implemented.");
    }
    async getEmbedding(prompt) {
        const payload = {
            model: this.model,
            prompt,
            options: {
                temperature: this.temperature,
                num_ctx: this.contextWindow,
                top_p: this.topP,
                ...this.additionalChatOptions
            }
        };
        const response = await fetch(`${this.baseURL}/api/embeddings`, {
            body: JSON.stringify(payload),
            method: "POST",
            signal: AbortSignal.timeout(this.requestTimeout),
            headers: {
                "Content-Type": "application/json"
            }
        });
        const { embedding } = await response.json();
        return embedding;
    }
    async getTextEmbedding(text) {
        return this.getEmbedding(text);
    }
    async getQueryEmbedding(query) {
        return this.getEmbedding(query);
    }
}
