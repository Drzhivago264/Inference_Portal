import { encodingForModel } from "js-tiktoken";
import { randomUUID } from "@llamaindex/env";
export var Tokenizers;
(function(Tokenizers) {
    Tokenizers["CL100K_BASE"] = "cl100k_base";
})(Tokenizers || (Tokenizers = {}));
/**
 * Helper class singleton
 */ class GlobalsHelper {
    defaultTokenizer = null;
    initDefaultTokenizer() {
        const encoding = encodingForModel("text-embedding-ada-002"); // cl100k_base
        this.defaultTokenizer = {
            encode: (text)=>{
                return new Uint32Array(encoding.encode(text));
            },
            decode: (tokens)=>{
                const numberArray = Array.from(tokens);
                const text = encoding.decode(numberArray);
                const uint8Array = new TextEncoder().encode(text);
                return new TextDecoder().decode(uint8Array);
            }
        };
    }
    tokenizer(encoding) {
        if (encoding && encoding !== "cl100k_base") {
            throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
        }
        if (!this.defaultTokenizer) {
            this.initDefaultTokenizer();
        }
        return this.defaultTokenizer.encode.bind(this.defaultTokenizer);
    }
    tokenizerDecoder(encoding) {
        if (encoding && encoding !== "cl100k_base") {
            throw new Error(`Tokenizer encoding ${encoding} not yet supported`);
        }
        if (!this.defaultTokenizer) {
            this.initDefaultTokenizer();
        }
        return this.defaultTokenizer.decode.bind(this.defaultTokenizer);
    }
    createEvent({ parentEvent, type, tags }) {
        return {
            id: randomUUID(),
            type,
            // inherit parent tags if tags not set
            tags: tags || parentEvent?.tags,
            parentId: parentEvent?.id
        };
    }
}
export const globalsHelper = new GlobalsHelper();
