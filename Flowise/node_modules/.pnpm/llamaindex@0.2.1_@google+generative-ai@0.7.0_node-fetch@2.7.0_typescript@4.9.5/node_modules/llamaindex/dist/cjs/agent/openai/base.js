"use strict";
Object.defineProperty(exports, "__esModule", {
    value: true
});
Object.defineProperty(exports, "OpenAIAgent", {
    enumerable: true,
    get: function() {
        return OpenAIAgent;
    }
});
const _index = require("../../llm/index.js");
const _base = require("../runner/base.js");
const _worker = require("./worker.js");
class OpenAIAgent extends _base.AgentRunner {
    constructor({ tools, llm, memory, prefixMessages, verbose, maxFunctionCalls = 5, defaultToolChoice = "auto", callbackManager, toolRetriever, systemPrompt }){
        llm = llm ?? new _index.OpenAI({
            model: "gpt-3.5-turbo-0613"
        });
        if (systemPrompt) {
            if (prefixMessages) {
                throw new Error("Cannot provide both systemPrompt and prefixMessages");
            }
            prefixMessages = [
                {
                    content: systemPrompt,
                    role: "system"
                }
            ];
        }
        if (!llm?.metadata.isFunctionCallingModel) {
            throw new Error("LLM model must be a function-calling model");
        }
        const stepEngine = new _worker.OpenAIAgentWorker({
            tools,
            callbackManager,
            llm,
            prefixMessages,
            maxFunctionCalls,
            toolRetriever,
            verbose
        });
        super({
            agentWorker: stepEngine,
            memory,
            callbackManager,
            defaultToolChoice,
            chatHistory: prefixMessages
        });
    }
}
