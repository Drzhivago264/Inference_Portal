import { getHistory } from "../../ChatHistory.js";
import { Response } from "../../Response.js";
import { OpenAI } from "../../llm/index.js";
import { streamConverter, streamReducer } from "../../llm/utils.js";
/**
 * SimpleChatEngine is the simplest possible chat engine. Useful for using your own custom prompts.
 */ export class SimpleChatEngine {
    chatHistory;
    llm;
    constructor(init){
        this.chatHistory = getHistory(init?.chatHistory);
        this.llm = init?.llm ?? new OpenAI();
    }
    async chat(params) {
        const { message, stream } = params;
        const chatHistory = params.chatHistory ? getHistory(params.chatHistory) : this.chatHistory;
        chatHistory.addMessage({
            content: message,
            role: "user"
        });
        if (stream) {
            const stream = await this.llm.chat({
                messages: await chatHistory.requestMessages(),
                stream: true
            });
            return streamConverter(streamReducer({
                stream,
                initialValue: "",
                reducer: (accumulator, part)=>accumulator += part.delta,
                finished: (accumulator)=>{
                    chatHistory.addMessage({
                        content: accumulator,
                        role: "assistant"
                    });
                }
            }), (r)=>new Response(r.delta));
        }
        const response = await this.llm.chat({
            messages: await chatHistory.requestMessages()
        });
        chatHistory.addMessage(response.message);
        return new Response(response.message.content);
    }
    reset() {
        this.chatHistory.reset();
    }
}
