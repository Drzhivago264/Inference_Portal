import { getHistory } from "../../ChatHistory.js";
import { defaultCondenseQuestionPrompt, messagesToHistoryStr } from "../../Prompt.js";
import { serviceContextFromDefaults } from "../../ServiceContext.js";
import { extractText, streamReducer } from "../../llm/utils.js";
import { PromptMixin } from "../../prompts/index.js";
/**
 * CondenseQuestionChatEngine is used in conjunction with a Index (for example VectorStoreIndex).
 * It does two steps on taking a user's chat message: first, it condenses the chat message
 * with the previous chat history into a question with more context.
 * Then, it queries the underlying Index using the new question with context and returns
 * the response.
 * CondenseQuestionChatEngine performs well when the input is primarily questions about the
 * underlying data. It performs less well when the chat messages are not questions about the
 * data, or are very referential to previous context.
 */ export class CondenseQuestionChatEngine extends PromptMixin {
    queryEngine;
    chatHistory;
    llm;
    condenseMessagePrompt;
    constructor(init){
        super();
        this.queryEngine = init.queryEngine;
        this.chatHistory = getHistory(init?.chatHistory);
        this.llm = init?.serviceContext?.llm ?? serviceContextFromDefaults().llm;
        this.condenseMessagePrompt = init?.condenseMessagePrompt ?? defaultCondenseQuestionPrompt;
    }
    _getPrompts() {
        return {
            condenseMessagePrompt: this.condenseMessagePrompt
        };
    }
    _updatePrompts(promptsDict) {
        if (promptsDict.condenseMessagePrompt) {
            this.condenseMessagePrompt = promptsDict.condenseMessagePrompt;
        }
    }
    async condenseQuestion(chatHistory, question) {
        const chatHistoryStr = messagesToHistoryStr(await chatHistory.requestMessages());
        return this.llm.complete({
            prompt: this.condenseMessagePrompt({
                question: question,
                chatHistory: chatHistoryStr
            })
        });
    }
    async chat(params) {
        const { message, stream } = params;
        const chatHistory = params.chatHistory ? getHistory(params.chatHistory) : this.chatHistory;
        const condensedQuestion = (await this.condenseQuestion(chatHistory, extractText(message))).text;
        chatHistory.addMessage({
            content: message,
            role: "user"
        });
        if (stream) {
            const stream = await this.queryEngine.query({
                query: condensedQuestion,
                stream: true
            });
            return streamReducer({
                stream,
                initialValue: "",
                reducer: (accumulator, part)=>accumulator += part.response,
                finished: (accumulator)=>{
                    chatHistory.addMessage({
                        content: accumulator,
                        role: "assistant"
                    });
                }
            });
        }
        const response = await this.queryEngine.query({
            query: condensedQuestion
        });
        chatHistory.addMessage({
            content: response.response,
            role: "assistant"
        });
        return response;
    }
    reset() {
        this.chatHistory.reset();
    }
}
