import { randomUUID } from "@llamaindex/env";
import { defaultContextSystemPrompt } from "../../Prompt.js";
import { PromptMixin } from "../../prompts/index.js";
export class DefaultContextGenerator extends PromptMixin {
    retriever;
    contextSystemPrompt;
    nodePostprocessors;
    constructor(init){
        super();
        this.retriever = init.retriever;
        this.contextSystemPrompt = init?.contextSystemPrompt ?? defaultContextSystemPrompt;
        this.nodePostprocessors = init.nodePostprocessors || [];
    }
    _getPrompts() {
        return {
            contextSystemPrompt: this.contextSystemPrompt
        };
    }
    _updatePrompts(promptsDict) {
        if (promptsDict.contextSystemPrompt) {
            this.contextSystemPrompt = promptsDict.contextSystemPrompt;
        }
    }
    async applyNodePostprocessors(nodes, query) {
        let nodesWithScore = nodes;
        for (const postprocessor of this.nodePostprocessors){
            nodesWithScore = await postprocessor.postprocessNodes(nodesWithScore, query);
        }
        return nodesWithScore;
    }
    async generate(message, parentEvent) {
        if (!parentEvent) {
            parentEvent = {
                id: randomUUID(),
                type: "wrapper",
                tags: [
                    "final"
                ]
            };
        }
        const sourceNodesWithScore = await this.retriever.retrieve({
            query: message,
            parentEvent
        });
        const nodes = await this.applyNodePostprocessors(sourceNodesWithScore, message);
        return {
            message: {
                content: this.contextSystemPrompt({
                    context: nodes.map((r)=>r.node.text).join("\n\n")
                }),
                role: "system"
            },
            nodes
        };
    }
}
