<!DOCTYPE HTML>
<html>

<head>
  <title>User Manual</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
  <link rel="shortcut icon" type="image/png" href="static/image/favicon.ico" />
  <meta property="og:title" content="Inference Portal for multiple Large Language Models">
  <meta property="og:description" content="Inference Portal that offers API, Chat Bot Mode and more for multiple large language modelS">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://professorparakeet.com/static/image/android-chrome-192x192.png">
  <meta property="og:image" content="https://professorparakeet.com/static/image/android-chrome-192x192.png"/>
  <link rel="stylesheet" href="static/css/pico-main/css/pico.min.css" />
  <link rel="stylesheet" href="static/css/pico-main/css/pico.colors.min.css" />
  <link href="static/css/prism.css" rel="stylesheet" />
  <script src="static/js/prism.js"></script>
</head>

<body>
  <header class="container">
    <nav>
      <ul>
        <hgroup  onclick="window.location.href = '/';">
          <h1><b>Inference</b></h1>
        </hgroup>
      </ul>
      <ul>
        <li>
          <details  class="dropdown">
            <summary role="button" class="outline">
              About
            </summary>
            <ul dir="rtl">
              <li><a  href="/">Introduction</a></li>
              <li><a  href="/model_infor">Model</a></li>
              <li><a aria-current="page" href="/manual">User Manual</a></li>
              <li><a href="/contact">Contact Us</a></li>
            </ul>
          </details> 
        </li>
       
        <li>
          <details  class="dropdown">
            <summary>
              Modes
            </summary>
            <ul dir="rtl">
              <li><a href="/prompt">Prompt and API</a></li>
              <li><a href="/chat">Chat Bot and Agent</a></li>
            </ul>
          </details>
        </li> 
        <li><a class="contrast" href="/buy">Get Key</a></li>
        <li><a class="contrast" href="/promptresponse">Response Log</a></li>
        
      </ul>
      
    </nav>
  
  </header>
  <hr>
  <main class="container">

      
      <div id="content" class="container">
        <!-- insert the page content here -->
        <h1>What can this website do?</h1>
        <p> This website is trying to sell you the access to several language models. The users can access the language
          models via three modes below: </p>
        <h1>API endpoints</h1>
        <p> This website fowards your request to the GPU servers and return the results. </p>
        <div class="grid">
          <div class="container">
            <h4>Python example for chat endpoint:</h4>
            <pre style="font-size: 14px;"><code class="language-Python" data-prismjs-copy="Copy" >r = requests.post("https://professorparakeet.com/api/chat", headers={"Authorization": "Bearer str"}, 
json={"prompt": str,
      "model" : str,
      'top_k': int,
      'top_p': float,
      'best_of': int,
      'max_tokens': int,
      'frequency_penalty': float,
      'presence_penalty': float,
      'temperature': float,
      'beam': bool,
      'early_stopping': bool,
      'length_penalty': float
}) 
print(r.json())
            </code></pre>
          </div>
          <div clas="container">
            <h4>cURL example for text completion endpoint:</h4>
            <pre style="font-size: 14px;"><code class="language-bash" >curl "https://professorparakeet.com/api/completion" --request POST \
-H "Authorization: Bearer str" -H 'Content-Type: application/json' \
--data-binary '{"prompt": str, 
                "model" : str,
                "top_k": int,
                "top_p": float,
                "best_of": int,
                "max_tokens": int,
                "frequency_penalty": float,
                "presence_penalty": float,
                "temperature": float,
                "beam": bool,
                "early_stopping": bool,
                "length_penalty": float
              }'
              </code></pre>
          </div>
        </div> <br>
        <div class="grid">
        <div class="container">
          <h4> You can also stream our response in chat API. </h4>
          <pre style="font-size: 14px;"><code class="language-Python" data-prismjs-copy="Copy" >r = requests.post("https://professorparakeet.com/api/chat", 
headers={"Authorization": "Bearer str"}, 
json={"prompt": "What is 1 + 1?",
      "model" : str,
      'stream': True,
    }, stream=True) 
for chunk in response.iter_lines():
    if chunk:
        print(chunk)
  </code></pre>
  </div>
  <div clas="container">
    <h4>Sample Stream Output:</h4>
    <pre style="font-size: 14px;"><code class="language-bash" >b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1']}, 'delta': '1'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 +']}, 'delta': '1 +'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1']}, 'delta': '1 + 1'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is']}, 'delta': '1 + 1 is'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is equal']}, 'delta': '1 + 1 is equal'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is equal to']}, 'delta': '1 + 1 is equal to'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is equal to ']}, 'delta': '1 + 1 is equal to '}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is equal to 2']}, 'delta': '1 + 1 is equal to 2'}"
b"{'response': {'text': ['Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\\n### Instruction:\\nwhat is 1 + 1?\\n\\n### Response:\\n\\n1 + 1 is equal to 2.']}, 'delta': '1 + 1 is equal to 2.'}"
      </code></pre>
  </div>
</div>
        </div>
        <small><i>NOTE: Streamming is only available in chat mode.</i></small><br>
        <small><i>NOTE: If the server is currently offline, you should send a warm up request to boot it up, otherwise you
          will get a lot a status reponses for your prompts.</i></small>
        <h1>Chat Bot Mode</h1>
        <p>We offer standard chatbot mode with custom chat template. We use a vectorised database to store 5 previous model's responses and query them to answer your questions.
        </p>
        <p>
          The maximum context length is 4096 tokens, please do not input a 10000-page book into the chatroom, the model will give you nothing. </p>
        <h1>Hard Core Prompt Engineering Mode</h1>
        <p>We are working on a feature that use Lagent to split our model into multiple smart workers for complicated
          tasks that require multiple reasoning steps.
          User can participate into the creation of such prompts for their own tasks.
          You can contribute or chew gum. </p>
        <h1>The behaviors of this website</h1>
        <ul>
          <li>This website dynamically boot up GPU servers on users' demands</li>
          <li>1200 seconds from the last resonpses, GPU servers are automatically shut down. </li>
          <li>GPU servers are kept running if there is a constant demand. </li>
          <li>Global Rate Limit is 3 requests/second. API Rate Limit is 5 requests/second </li>
          <li>You can check and collect your promptresponse log in <a href="/promptresponse">Response Log</a>.
          </li>
        </ul>
        </ul>
      </div>
 

  </main>
</body>

</html>