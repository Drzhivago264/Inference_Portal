{% extends "component_html/base.html" %}
{% block head %}
<link rel="stylesheet" href="/static/css/chatbot.css">
{% endblock head %}

{% block content%}
<main class="container grid" style="grid-template-columns: 70% 30%;">
    <div class="container">
        <div id="chat-log">
            <div class="message_log_container"
                style="text-align: left;word-wrap: break-word; overflow-wrap: break-word;">
                <span> Input your API Key:
                    <input style="width: 20ch; height: 20px;" id="api_key">
                </span>
            </div>
            <div id="chat-log_">

            </div>

        </div>
        <hr>
        <div class="input-wrapper">
            <textarea id="chat-message-input" name="message"></textarea>
            <button id="chat-message-submit">Send</button>
        </div>
        {{ name|json_script:"name" }}
        {{ key|json_script:"key" }}
    </div>
    <div class="container">
        <h3> Available Models </h3>
        {% for llm in llms %}
        {% if llm.name == 'Mistral Chat 13B' %}
        <input type="radio" class="checkbox" name="model" value="{{llm.name}}" checked="checked"> {{llm.name}}<br>
        {% else %}
        <input type="radio" class="checkbox" name="model" value="{{llm.name}}"> {{llm.name}}<br>
        {% endif %}
        {% endfor %}
        <h3> Parameters </h3>
        <input type="radio" class="checkbox_mode" name="mode" value="chat" checked="checked"> Chat Bot Mode<br>
        <input type="radio" class="checkbox_mode" name="mode" value="generate"> Sentence Completion<br>
        <input type="checkbox" class="checkbox_include_memory" name="include_memory" id="include_memory" checked>
        Include Memory (for chat mode) <br>
        <hr>
        <small><i>NOTE: If the default parameters does not work for you, you can adjust them here.</i></small> <br>
        <small><i>NOTE: In order to better understand these parameters, refer to <a
                    href='https://huggingface.co/blog/how-to-generate'> This Blog </a> or <a
                    href='https://github.com/vllm-project/vllm/blob/main/vllm/sampling_params.py'> This Code. </a>
            </i></small>
        <hr>
        <label for="top_p">Top_p:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step=".001" name="top_p" min="0.01" max="1" value="0.73"
                oninput="this.nextElementSibling.value = parseFloat(this.value).toFixed(2)">
            <output>0.73</output>
        </div><br>
        <label for="top_k">Top_k:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step="1" name="top_k" min="0" max="100" value="0"
                oninput="this.nextElementSibling.value = this.value">
            <output>-1</output>
        </div><br>
        <label for="max_tokens">Max_tokens:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step="1" name="max_tokens" min="1" max="4096" value="128"
                oninput="this.nextElementSibling.value = this.value">
            <output>128</output>
        </div><br>


        <label for="temperature">Temperature:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step=".001" name="temperature" min="0" max="1.0" value="0.72"
                oninput="this.nextElementSibling.value = parseFloat(this.value).toFixed(2)">
            <output>0.72</output>
        </div><br>
        <label for="frequency_penalty">Frequency penalty:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step=".001" name="frequency_penalty" min="-2.0" max="2.0" value="0"
                oninput="this.nextElementSibling.value = parseFloat(this.value).toFixed(2)">
            <output>0</output>
        </div><br>
        <label for="presence_penalty">Presence penalty:</label>
        <div class="grid" style="grid-template-columns: 80% 20%;">
            <input type="range" step=".001" name="presence_penalty" min="-2.0" max="2.0" value="0"
                oninput="this.nextElementSibling.value = parseFloat(this.value).toFixed(2)">
            <output>0</output>
        </div>

        <hr>
        <small><i>NOTE: These parameters go along with each others, please know what you are doing.</i></small><br>
        <small><i>NOTE: Return to default value if you messed up the parameters</i></small>
        <hr>
        <input type="checkbox" class="checkbox_beam" name="beam" id="beam"> Beam Search (default = False) <br>
        <input type="checkbox" class="checkbox_early_stopping" name="early_stopping" id="early_stopping"> Early
        Stop (default = False) <br><br>
        <input style="width: 10ch;" type="number" step="0.01" name="length_penalty" min="-2.0" max="2.0" value="0">
        Length Penalty
        (default = 0)<br>
        <input style="width: 10ch;" type="number" step="1" name="best_of" min="1" max="5" value="2"> Best of
        (default = 2 for beam
        search, 1 for sampling) <br>
    </div>
</main>
<script>
    const key = JSON.parse(document.getElementById('key').textContent);
    var ws_scheme = window.location.protocol == "https:" ? "wss" : "ws";
    const chatSocket = new WebSocket(
        ws_scheme
        + '://'
        + window.location.host
        + '/ws/{{destination}}/'
        + key
        + '/'
    );
    chatSocket.onmessage = function (e) {
        const data = JSON.parse(e.data);
        if (data.role == 'Human') {
            document.querySelector('#chat-log_').innerHTML += ('<div class="message_log_container" style="text-align: right;word-wrap: break-word; overflow-wrap: break-word;">  <span>' + " (" + data.role + "-" + data.time + ") " + data.message.replace(/\n/g, "<br>") + '</span></div> ');
        }
        else if (data.holder) {
            document.querySelector('#chat-log_').innerHTML += ('<div class="message_log_container" id =' + data.holderid + ' style="text-align: left;word-wrap: break-word; overflow-wrap: break-word;">  <span>' + data.role + "-" + data.time + ": " + '</span></div> ');
        }
        else if (data.stream_id) {
            document.getElementById(data.stream_id).innerHTML += data.message.replace(/\n/g, "<br>")
        }
        else {
            document.querySelector('#chat-log_').innerHTML += ('<div class="message_log_container" style="text-align: left;word-wrap: break-word; overflow-wrap: break-word;">  <span>' + data.message.replace(/\n/g, "<br>") + " (" + data.role + "-" + data.time + ") " + '</span></div> ');

        }
        logTa = document.getElementById("chat-log")
        logTa.scrollTop = logTa.scrollHeight;

    };

    chatSocket.onclose = function (e) {
        console.error('Chat socket closed unexpectedly');
    };
    var textarea = document.getElementById("chat-message-input");
    var textarea_submit_button = document.querySelector('#chat-message-submit')
    textarea.focus();
    textarea.onkeyup = function (e) {
        if (e.keyCode === 13 && !e.shiftKey) {
            textarea_submit_button.click();
        }
    };
    var textarea_size_litmit = 300;
    textarea.oninput = function () {
        textarea.style.height = "";
        textarea.style.height = Math.min(textarea.scrollHeight, textarea_size_litmit) + "px";
    };
    textarea_submit_button.onclick = function (e) {
        var choosen_models = null;
        var inputElements = document.getElementsByClassName('checkbox');
        for (var i = 0; inputElements[i]; ++i) {
            if (inputElements[i].checked) {
                choosen_models = inputElements[i].value;
                break;
            }
        }
        var mode = null;
        var modeElements = document.getElementsByClassName('checkbox_mode');
        for (var i = 0; modeElements[i]; ++i) {
            if (modeElements[i].checked) {
                mode = modeElements[i].value;
                break;
            }
        }
        const api_key = document.getElementById('api_key').value
        const top_p = document.getElementsByName("top_p")[0].value
        var top_k = document.getElementsByName("top_k")[0].value
        if (top_k <= 0) {
            top_k = -1
        }
        const best_of = document.getElementsByName("best_of")[0].value
        const max_tokens = document.getElementsByName("max_tokens")[0].value
        const temperature = document.getElementsByName("temperature")[0].value
        if (document.getElementById('include_memory').checked) {
            include_memory = true
        } else {
            include_memory = false
        }
        const frequency_penalty = document.getElementsByName("frequency_penalty")[0].value
        const presence_penalty = document.getElementsByName("presence_penalty")[0].value
        if (document.getElementById('beam').checked) {
            beam = true
        } else {
            beam = false
        }
        if (document.getElementById('early_stopping').checked) {
            early_stopping = true
        } else {
            early_stopping = false
        }
        const length_penalty = document.getElementsByName("length_penalty")[0].value
        const message = textarea.value;
        if (message.trim() !== "") {
            chatSocket.send(JSON.stringify({
                'mode': mode,
                'message': message,
                'key': api_key,
                'choosen_models': choosen_models,
                'role': 'Human',
                'top_k': top_k,
                'top_p': parseFloat(top_p).toFixed(2),
                'best_of': best_of,
                'max_tokens': max_tokens,
                'frequency_penalty': parseFloat(frequency_penalty).toFixed(2),
                'presence_penalty': parseFloat(presence_penalty).toFixed(2),
                'temperature': parseFloat(temperature).toFixed(2),
                'beam': beam,
                'early_stopping': early_stopping,
                'length_penalty': parseFloat(length_penalty).toFixed(2),
                'include_memory': include_memory
            }));
            textarea.value = '';
        }
    };
</script>
{% endblock content%}